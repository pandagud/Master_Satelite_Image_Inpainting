{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T10:50:40.296060Z",
     "start_time": "2021-05-12T10:50:38.776411Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import rasterio\n",
    "import geopandas\n",
    "import glob\n",
    "import fiona\n",
    "import geojson\n",
    "import shapely.geometry\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from sentinelsat import read_geojson\n",
    "from datetime import timedelta\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon\n",
    "from geojson import FeatureCollection,dump\n",
    "from rasterio.mask import mask\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T10:50:40.325390Z",
     "start_time": "2021-05-12T10:50:40.298207Z"
    }
   },
   "outputs": [],
   "source": [
    "## Clip methods\n",
    "def deleteFolder(path):\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError as e:\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "\n",
    "def showSatImage(path):\n",
    "        src = rasterio.open(path)\n",
    "        titlestring = str(src.crs.data['init'])\n",
    "        show(src,transform=src.transform,title=titlestring,with_bounds=True)\n",
    "        print('Height ' +str(src.height))\n",
    "        print('Width ' + str(src.width))\n",
    "        print('Spatial res ' + str(src.res[0]) +','+str(src.res[1]))\n",
    "        print('Area ' + str(src.bounds))\n",
    "\n",
    "def clip_optic_image(baseInPath,baseOutPath,aoi,bandName,band='',transform=None,height=None,width=None):\n",
    "\n",
    "        with rasterio.open(baseInPath + band) as img:\n",
    "            #outbool,outtransform,outwindow = rasterio.mask.raster_geometry_mask(img, aoi,crop=True)\n",
    "            out_img, out_transform= mask(img, aoi,crop=True)\n",
    "\n",
    "        # use the metadata from our original mosaic\n",
    "        meta = img.meta.copy()\n",
    "        if transform!=None:\n",
    "            out_transform=transform\n",
    "\n",
    "        # update metadata with new, clipped mosaic's boundaries\n",
    "        meta.update({\"driver\": \"GTiff\",\n",
    "                    \"transform\": out_transform,\n",
    "                     \"height\": height,\n",
    "                     \"width\": width})\n",
    "        end_path = baseOutPath + '//'+bandName+'.tif'\n",
    "        # write the clipped-and-cropped dataset to a new GeoTIFF\n",
    "        with rasterio.open(end_path, 'w', **meta) as dst:\n",
    "            dst.write(out_img)\n",
    "        return end_path\n",
    "        \n",
    "def clip_image(baseInPath,baseOutPath,aoi,bandName,band=''):\n",
    "\n",
    "        with rasterio.open(baseInPath + band) as img:\n",
    "            #outbool,outtransform,outwindow = rasterio.mask.raster_geometry_mask(img, aoi,crop=True)\n",
    "            out_img, out_transform= mask(img, aoi,crop=True)\n",
    "\n",
    "        # use the metadata from our original mosaic\n",
    "        meta = img.meta.copy()\n",
    "\n",
    "        # update metadata with new, clipped mosaic's boundaries\n",
    "        meta.update({\"driver\": \"GTiff\",\n",
    "                    \"transform\": out_transform,\n",
    "                     \"height\": out_img.shape[1],\n",
    "                     \"width\": out_img.shape[2]})\n",
    "        end_path = baseOutPath + '//'+bandName+'.tif'\n",
    "        # write the clipped-and-cropped dataset to a new GeoTIFF\n",
    "        with rasterio.open(end_path, 'w', **meta) as dst:\n",
    "            dst.write(out_img)\n",
    "        return out_transform,end_path, out_img.shape[1],out_img.shape[2]\n",
    "def cog_image(baseInPath,baseOutPath):\n",
    "    if baseInPath == baseOutPath:\n",
    "        baseOutPath=baseOutPath.replace('.tif','')\n",
    "        baseOutPath=baseOutPath+'_cog.tif'        \n",
    "    !gdal_translate {baseInPath} {baseOutPath} -of COG -co COMPRESS=DEFLATE -co NUM_THREADS=ALL_CPUS -co BIGTIFF=YES --config GDAL_CACHEMAX 16384\n",
    "    \n",
    "def create_cog(img, factors=[2, 4, 8, 16, 32], compression='DEFLATE'):\n",
    "    # Define a new configuration, save the previous configuration,\n",
    "    # and then apply the new one.\n",
    "    new_config = {\n",
    "        'GDAL_CACHEMAX': '8192',\n",
    "        'COMPRESS_OVERVIEW': 'NONE'  # Compression will be made in the next step\n",
    "    }\n",
    "    prev_config = {\n",
    "        key: gdal.GetConfigOption(key) for key in new_config.keys()}\n",
    "    for key, val in new_config.items():\n",
    "        gdal.SetConfigOption(key, val)\n",
    "\n",
    "    InputImage = str(img)\n",
    "    Image = gdal.Open(InputImage, 1)  # 0 = read-only, 1 = read-write.\n",
    "    Image.BuildOverviews(\"NEAREST\", factors)\n",
    "    del Image\n",
    "\n",
    "    # Restore previous configuration.\n",
    "    for key, val in prev_config.items():\n",
    "        gdal.SetConfigOption(key, val)\n",
    "\n",
    "\n",
    "    # Run gdal_translate to properly tile and compress gtiff file after overviews have been added\n",
    "    # Note: Should not be necessary, but the current version of gdal destroys tiles when adding overviews\n",
    "    img_tmp = Path(img.parent, 'temp' + img.suffix)\n",
    "    img.rename(img_tmp)\n",
    "\n",
    "    ds = gdal.Open(str(img_tmp))  # img is a Path object but gdal requires a string, therefore str(img)\n",
    "    # NOTE: ZSTD and WEBP compression is not working here\n",
    "    # (https://lists.osgeo.org/pipermail/gdal-dev/2018-November/049289.html)\n",
    "    if compression == 'NONE':\n",
    "        creation_options = ['TILED=YES', 'COPY_SRC_OVERVIEWS=YES', 'BLOCKXSIZE=512', 'BLOCKYSIZE=512',\n",
    "                            'NUM_THREADS=ALL_CPUS', 'BIGTIFF=IF_SAFER']\n",
    "    elif compression == 'DEFLATE':\n",
    "        creation_options = ['COMPRESS=DEFLATE', 'TILED=YES', 'COPY_SRC_OVERVIEWS=YES',\n",
    "                            'BLOCKXSIZE=512', 'BLOCKYSIZE=512', 'NUM_THREADS=ALL_CPUS', 'BIGTIFF=YES']\n",
    "    elif compression == 'JPEG':\n",
    "        creation_options = ['COMPRESS=JPEG', 'PHOTOMETRIC=YCBCR', 'JPEG_QUALITY=90', 'TILED=YES',\n",
    "                            'COPY_SRC_OVERVIEWS=YES', 'BLOCKXSIZE=512', 'BLOCKYSIZE=512', 'NUM_THREADS=ALL_CPUS',\n",
    "                            'BIGTIFF=IF_SAFER']\n",
    "    config_options = ['GDAL_CACHEMAX=8192']\n",
    "    translate_options = gdal.TranslateOptions(creationOptions=creation_options)\n",
    "    ds = gdal.Translate(str(img), ds, options=translate_options, config_options=config_options)\n",
    "    ds = None\n",
    "\n",
    "    os.remove(img_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T10:50:40.385311Z",
     "start_time": "2021-05-12T10:50:40.327074Z"
    }
   },
   "outputs": [],
   "source": [
    "def downloadBiome(biome,outputPath,logger):\n",
    "    process_files = True\n",
    "    ## Using same data_dir\n",
    "    biome_geojson = str(biome)\n",
    "    data_dir = Path.cwd() / 'data'\n",
    "    current_order_id = 'test_order_' + datetime.datetime.today().strftime('%Y%m%d-%H%M%S')\n",
    "    \n",
    "    ## LTA down to only 30 days so using multiple accounts to trigger download. \n",
    "    userTuple = [['pandagud','damp4ever'],['pandagud2','damp4ever'],['pandagud3','damp4ever'],['au524478','Palantir1234']]\n",
    "    current_user = random.choice(userTuple)\n",
    "    print(current_user[0])\n",
    "    ## Downloading Sentinel-2\n",
    "    !python app.py --username {current_user[0]} --password {current_user[1]} --order_id {current_order_id} --data_directory data --geojson {biome_geojson} --satellite s2 --startdate 20200801 --enddate 20210501 --s2_num_proc 4 --s2_relative_orbit 0 --s2_max_cloudcoverage 1\n",
    "    ## based on Sentinel-2 geolocations we are downloading Sentinel-1\n",
    "    geojson_path = (data_dir / 'orders' / current_order_id).with_suffix('.geojson')\n",
    "    if not os.path.exists(geojson_path):\n",
    "        logger.info('################################################')\n",
    "        logger.info('No sentinel-2 product for this biome')\n",
    "        return\n",
    "    S2_geojson = read_geojson(geojson_path)\n",
    "    start_S1_date = S2_geojson.get('features')[0].get('properties').get('ingestiondate')\n",
    "    start_S1_date = start_S1_date.split('T')[0]\n",
    "    start_S1_date = datetime.datetime.strptime(start_S1_date, '%Y-%m-%d').date()\n",
    "    ## New end date for S1\n",
    "    end_S1_date = start_S1_date + timedelta(days=7)\n",
    "    start_S1_date = start_S1_date - timedelta(days=7)\n",
    "\n",
    "    start_S1_date_str = str(start_S1_date).replace('-','')\n",
    "    end_S1_date_str = str(end_S1_date).replace('-', '')\n",
    "\n",
    "    current_order_id_SAR='test_order_SAR' + datetime.datetime.today().strftime('%Y%m%d-%H%M%S')\n",
    "    \n",
    "    current_user = random.choice(userTuple)\n",
    "    \n",
    "    ## Downloading Sentinel-1\n",
    "    !python app.py --username {current_user[0]} --password {current_user[1]} --order_id {current_order_id_SAR} --s2_order_id {current_order_id} --data_directory data --geojson {geojson_path} --satellite s1 --startdate {start_S1_date_str} --enddate {end_S1_date_str} --s1_num_proc 4 --s1_del_intermediate True --s1_output_crs EPSG:3857 - Projected\n",
    "    \n",
    "    logger.info('#############')\n",
    "    ## Arosic med Sentinel-1 som ref\n",
    "    if process_files:\n",
    "        logger.info('Done downloading and preprocess - will clip now')\n",
    "        logger.info('#############')\n",
    "        ## Sentinel-2 pathing\n",
    "        data = geopandas.read_file(geojson_path)\n",
    "\n",
    "        product = data['title']\n",
    "        product = product.values[0]\n",
    "        Sentinel2_name = str(product)\n",
    "        utm_code = product[39:41]  # e.g. 10\n",
    "        latitude_band = product[41:42]  # e.g. S\n",
    "        square = product[42:44]  # e.g. DG\n",
    "        tile_path = data_dir / 'output_data' / 's2' / 'tiles' / utm_code / latitude_band / square\n",
    "        product_path = (tile_path / product).with_suffix('.SAFE')\n",
    "        granule_path = product_path / 'GRANULE'\n",
    "        if not os.path.exists(granule_path):\n",
    "            logger.info('################################################')\n",
    "            logger.info('No uncurrpoted sentinel-2 product for this biome')\n",
    "            return\n",
    "        files = [f for f in sorted(os.listdir(granule_path))]\n",
    "        granule_path = granule_path / str(files[0])\n",
    "        granule_path = granule_path / 'IMG_DATA'\n",
    "        ## Only getting R10m atm \n",
    "        granule_path_10m = granule_path /'R10m'\n",
    "        bands_path_10m = []\n",
    "        for band in glob.glob(str(granule_path_10m) + '/*B0*'):\n",
    "            bands_path_10m.append(os.path.basename(band))\n",
    "        bands_path_10m.sort()\n",
    "\n",
    "        baseInOpticPath = granule_path_10m\n",
    "        \n",
    "        ## Sentinel-1 pathing\n",
    "        baseInSarPath = (data_dir / 'output_data' / 's1' /'combined')\n",
    "        combined_there = False\n",
    "        for combinedSar in glob.glob(str(baseInSarPath) + '/*.tiaf'):\n",
    "            combined_there = True\n",
    "            baseInSarPath = str(combinedSar) ## Quick fix but there should only be one\n",
    "        if combined_there==False:\n",
    "            logger.info('################################################')\n",
    "            logger.info('No sentinel-1 product for this biome')\n",
    "            return\n",
    "        Sentinel1_name = Path(baseInSarPath).stem\n",
    "        \n",
    "        ## This is the output dir\n",
    "        baseOutPath = outputPath\n",
    "        output_path_SAR = baseOutPath + '/Sentinel1'\n",
    "        if not os.path.exists(output_path_SAR):\n",
    "            os.makedirs(output_path_SAR)\n",
    "        output_path_OPTIC = baseOutPath +'/Sentinel2'\n",
    "        if not os.path.exists(output_path_OPTIC):\n",
    "            os.makedirs(output_path_OPTIC)\n",
    "        band2 = '/'+str(bands_path_10m[0])\n",
    "        band3 = '/'+str(bands_path_10m[1])\n",
    "        band4 = '/'+str(bands_path_10m[2])\n",
    "        band8 = '/'+str(bands_path_10m[3])\n",
    "\n",
    "        ## Clipping Sentinel-1 and 2 based on their intersection Polygon. Storing this as a geojson \n",
    "        src = rasterio.open(str(baseInSarPath))\n",
    "        sar_polygon = shapely.geometry.box(*src.bounds,ccw=True)\n",
    "        src = rasterio.open(str(baseInOpticPath) + band2)\n",
    "        optic_polygon = shapely.geometry.box(*src.bounds, ccw=True)\n",
    "        intersection_poly = optic_polygon.intersection(sar_polygon)\n",
    "        ## Storing intersection geojson. We need to disc. if we want three geojson - one for Sentinel-1, 2 and intersection.\n",
    "        geom_in_geojson = []\n",
    "        geom_in_geojson.append(geojson.Feature(geometry=intersection_poly, properties={}))\n",
    "        feature_collection = FeatureCollection(geom_in_geojson)\n",
    "        pathToFile = str(baseOutPath) + '//intersection.geojson'\n",
    "        with open(pathToFile, 'w') as f:\n",
    "            dump(feature_collection, f)\n",
    "        geo_df = geopandas.GeoDataFrame.from_file(pathToFile)\n",
    "        geo_df = geo_df.geometry.scale(xfact=0.95, yfact=0.95) ## scaling down\n",
    "        geo_df.crs='EPSG:3857'\n",
    "        intersections_panda = geo_df.geometry[0]\n",
    "        geo_df.to_file(pathToFile,driver='GeoJSON')\n",
    "        with fiona.open(pathToFile) as f:\n",
    "            aoi = [feature[\"geometry\"] for feature in f]\n",
    "        list_cog_images = []\n",
    "        logger.info(\"CLIPPING and COG\")\n",
    "        sen1_transform ,sar_clipped_path, height, width = clip_image(str(baseInSarPath),str(output_path_SAR),aoi,str(Sentinel1_name) + 'sar')\n",
    "        list_cog_images.append(sar_clipped_path)\n",
    "        band2_clipped_path = clip_optic_image(str(baseInOpticPath),str(output_path_OPTIC),aoi,str(Sentinel2_name)+'_B02',band=band2,transform=sen1_transform,height=height,width=width)\n",
    "        list_cog_images.append(band2_clipped_path)\n",
    "\n",
    "        band3_clipped_path=clip_optic_image(str(baseInOpticPath),str(output_path_OPTIC), aoi, str(Sentinel2_name)+'_B03',band=band3,transform=sen1_transform,height=height,width=width)\n",
    "        list_cog_images.append(band3_clipped_path)\n",
    "\n",
    "        band4_clipped_path=clip_optic_image(str(baseInOpticPath),str(output_path_OPTIC), aoi,str(Sentinel2_name)+ '_B04',band=band4,transform=sen1_transform,height=height,width=width)\n",
    "        list_cog_images.append(band4_clipped_path)\n",
    "\n",
    "        band8_clipped_path=clip_optic_image(str(baseInOpticPath),str(output_path_OPTIC), aoi,str(Sentinel2_name)+ '_B08',band=band8,transform=sen1_transform,height=height,width=width)\n",
    "        list_cog_images.append(band8_clipped_path)\n",
    "\n",
    "        ##TESTING \n",
    "        #showSatImage(sar_clipped_path)\n",
    "        #showSatImage(band2_clipped_path)\n",
    "        ##TESTING \n",
    "        for i in list_cog_images:\n",
    "            print(str(i))\n",
    "            create_cog(Path(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T10:50:40.393096Z",
     "start_time": "2021-05-12T10:50:40.386931Z"
    }
   },
   "outputs": [],
   "source": [
    "logname = '/workspace/data_landset8/ForestTestNoDebug'\n",
    "logging.basicConfig(filename=logname + '.log',\n",
    "                    filemode='a',\n",
    "                    format='%(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(logname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T10:59:51.230478Z",
     "start_time": "2021-05-12T10:59:32.954940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandagud\n",
      "/workspace/DSD_paper_2020/SentinelProc/app/src/sentinelprocessors/s2processor.py:202: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  elif coreg_info is not 'coreg_error':  # Apply to other modes\n",
      "/workspace/DSD_paper_2020/SentinelProc/app/data\n",
      "I0512 10:59:40.231069 139681409169216 app.py:38] True\n",
      "test_order_20210512-105932\n",
      "I0512 10:59:40.231303 139681409169216 app.py:46] ####################################\n",
      "I0512 10:59:40.231395 139681409169216 app.py:47] # Initializing Sentinel downloader #\n",
      "I0512 10:59:40.231477 139681409169216 app.py:48] ####################################\n",
      "I0512 10:59:40.231556 139681409169216 app.py:49] Order id: test_order_20210512-105932\n",
      "I0512 10:59:40.231908 139681409169216 app.py:54] /workspace/data_landset8/unzipped/Forest/BC/LC80200462014005LGN00/LC80200462014005LGN00.geojson\n",
      "I0512 10:59:40.585815 139681409169216 sentinel.py:209] Found 0 products\n",
      "I0512 10:59:40.882905 139681409169216 sentinel.py:209] Found 8 products\n",
      "I0512 10:59:40.887739 139681409169216 downloader.py:156] Number of products = 1\n",
      "I0512 10:59:40.888135 139681409169216 downloader.py:157] Total size [GB] = 1.05\n",
      "I0512 10:59:40.899754 139681409169216 app.py:72] \n",
      "I0512 10:59:40.900005 139681409169216 app.py:75] ####################\n",
      "I0512 10:59:40.900200 139681409169216 app.py:76] # Downloading data #\n",
      "I0512 10:59:40.900378 139681409169216 app.py:77] ####################\n",
      "I0512 10:59:40.908499 139681409169216 downloader.py:186] Downloading Sentinel-1/2/3 products\n",
      "I0512 10:59:40.912621 139681409169216 sentinel.py:728] Will download 1 products using 2 workers\n",
      "I0512 10:59:41.369635 139679762511616 sentinel.py:884] 2ec621f4-dbaa-43a3-8c1e-773aeaed9443 is online. Starting download\n",
      "I0512 10:59:41.580758 139679762511616 sentinel.py:576] Downloading 2ec621f4-dbaa-43a3-8c1e-773aeaed9443 to /workspace/DSD_paper_2020/SentinelProc/app/data/zipfiles/S2B_MSIL2A_20210330T161829_N0300_R040_T16QBH_20210330T203248.zip\n",
      "I0512 10:59:41.581656 139681409169216 downloader.py:199] No Sentinel-5p products found in query\n",
      "I0512 10:59:41.583373 139681409169216 app.py:79] \n",
      "I0512 10:59:41.586625 139681409169216 app.py:85] ###################\n",
      "I0512 10:59:41.586993 139681409169216 app.py:86] # Processing data #\n",
      "I0512 10:59:41.587282 139681409169216 app.py:87] ###################\n",
      "I0512 10:59:41.601121 139681409169216 processpipeliner.py:47] ### Processing Sentinel-2 products ###\n",
      "I0512 10:59:41.646851 139681409169216 base.py:31] BadZipfile for product S2B_MSIL2A_20210330T161829_N0300_R040_T16QBH_20210330T203248\n",
      "\n",
      "\u001b[m\u001b[1;30m--------------------------------------------------------------------------------\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m103 \u001b[1;34m<module>\n",
      "\u001b[m\u001b[1;37mapp.run(main)\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m300 \u001b[1;34mrun\n",
      "\u001b[m\u001b[1;37m_run_main(main, args)\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m251 \u001b[1;34m_run_main\n",
      "\u001b[m\u001b[1;37msys.exit(main(argv))\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m89 \u001b[1;34mmain\n",
      "\u001b[m\u001b[1;37mprocesspipeliner.process_products()\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mprocesspipeliner.py \u001b[1;32m56 \u001b[1;34mprocess_products\n",
      "\u001b[m\u001b[1;37mpool.map(s2processor.process_tiles, index_arg)\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mpool.py \u001b[1;32m364 \u001b[1;34mmap\n",
      "\u001b[m\u001b[1;37mreturn self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mpool.py \u001b[1;32m771 \u001b[1;34mget\n",
      "\u001b[m\u001b[1;37mraise self._value\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mpool.py \u001b[1;32m125 \u001b[1;34mworker\n",
      "\u001b[m\u001b[1;37mresult = (True, func(*args, **kwds))\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mpool.py \u001b[1;32m48 \u001b[1;34mmapstar\n",
      "\u001b[m\u001b[1;37mreturn list(map(*args))\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36ms2processor.py \u001b[1;32m28 \u001b[1;34mprocess_tiles\n",
      "\u001b[m\u001b[1;37mproduct = self.__concat_resolutions_paths(product)  # Must be done after unzipping (damnit ESA!)\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36ms2processor.py \u001b[1;32m37 \u001b[1;34m__concat_resolutions_paths\n",
      "\u001b[m\u001b[1;37mresolutions_path = list(granule_path.glob('*/'))[0] / 'IMG_DATA'\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;31mIndexError:\n",
      "\u001b[1;33mlist index out of range\n",
      "\u001b[m\u001b[0m/workspace/DSD_paper_2020/SentinelProc/app/src/sentinelprocessors/s2processor.py:202: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  elif coreg_info is not 'coreg_error':  # Apply to other modes\n",
      "/workspace/DSD_paper_2020/SentinelProc/app/data\n",
      "I0512 10:59:49.288315 139920513722176 app.py:38] True\n",
      "test_order_SAR20210512-105942\n",
      "I0512 10:59:49.288529 139920513722176 app.py:46] ####################################\n",
      "I0512 10:59:49.288623 139920513722176 app.py:47] # Initializing Sentinel downloader #\n",
      "I0512 10:59:49.288708 139920513722176 app.py:48] ####################################\n",
      "I0512 10:59:49.288790 139920513722176 app.py:49] Order id: test_order_SAR20210512-105942\n",
      "I0512 10:59:49.289137 139920513722176 app.py:54] /workspace/DSD_paper_2020/SentinelProc/app/data/orders/test_order_20210512-105932.geojson\n",
      "MULTIPOLYGON(((-89.8633 19.7851,-88.8159 19.7988,-88.8275 20.7905,-89.8816 20.7760,-89.8633 19.7851)))\n",
      "I0512 10:59:49.614020 139920513722176 sentinel.py:209] Found 9 products\n",
      "Found 9 products\n",
      "Reduced the products to 2 products\n",
      "I0512 10:59:49.629784 139920513722176 downloader.py:156] Number of products = 2\n",
      "I0512 10:59:49.630051 139920513722176 downloader.py:157] Total size [GB] = 3.2\n",
      "I0512 10:59:49.638136 139920513722176 app.py:72] \n",
      "I0512 10:59:49.638351 139920513722176 app.py:75] ####################\n",
      "I0512 10:59:49.638503 139920513722176 app.py:76] # Downloading data #\n",
      "I0512 10:59:49.638648 139920513722176 app.py:77] ####################\n",
      "I0512 10:59:49.644373 139920513722176 downloader.py:186] Downloading Sentinel-1/2/3 products\n",
      "I0512 10:59:49.647203 139920513722176 sentinel.py:728] Will download 2 products using 2 workers\n",
      "I0512 10:59:50.282420 139918867486464 sentinel.py:884] 09a8cd86-8373-4d0a-940f-827ce95b0d32 is online. Starting download\n",
      "I0512 10:59:50.390588 139918859093760 sentinel.py:884] c34d11d7-8ed9-4a88-bf67-6875651a0bca is online. Starting download\n",
      "I0512 10:59:50.483351 139918867486464 sentinel.py:576] Downloading 09a8cd86-8373-4d0a-940f-827ce95b0d32 to /workspace/DSD_paper_2020/SentinelProc/app/data/zipfiles/S1A_IW_GRDH_1SDV_20210331T000751_20210331T000816_037235_0462B3_4A2D.zip\n",
      "I0512 10:59:50.569508 139918859093760 sentinel.py:576] Downloading c34d11d7-8ed9-4a88-bf67-6875651a0bca to /workspace/DSD_paper_2020/SentinelProc/app/data/zipfiles/S1A_IW_GRDH_1SDV_20210331T000726_20210331T000751_037235_0462B3_6292.zip\n",
      "I0512 10:59:50.570436 139920513722176 downloader.py:199] No Sentinel-5p products found in query\n",
      "I0512 10:59:50.572122 139920513722176 app.py:79] \n",
      "I0512 10:59:50.575039 139920513722176 app.py:85] ###################\n",
      "I0512 10:59:50.575405 139920513722176 app.py:86] # Processing data #\n",
      "I0512 10:59:50.575693 139920513722176 app.py:87] ###################\n",
      "I0512 10:59:50.591879 139920513722176 processpipeliner.py:27] ### Processing Sentinel-1 products ###\n",
      "I0512 10:59:50.635723 139920513722176 s1processor.py:31] Processing product: S1A_IW_GRDH_1SDV_20210331T000726_20210331T000751_037235_0462B3_6292\n",
      "I0512 10:59:50.635719 139920513722176 s1processor.py:31] Processing product: S1A_IW_GRDH_1SDV_20210331T000751_20210331T000816_037235_0462B3_4A2D\n",
      "I0512 10:59:50.637694 139920513722176 base.py:31] BadZipfile for product S1A_IW_GRDH_1SDV_20210331T000726_20210331T000751_037235_0462B3_6292\n",
      "I0512 10:59:50.637728 139920513722176 base.py:31] BadZipfile for product S1A_IW_GRDH_1SDV_20210331T000751_20210331T000816_037235_0462B3_4A2D\n",
      "E0512 10:59:50.638100 139920513722176 s1processor.py:48] An error occured during proccesing of: S1A_IW_GRDH_1SDV_20210331T000726_20210331T000751_037235_0462B3_6292\n",
      "E0512 10:59:50.638134 139920513722176 s1processor.py:48] An error occured during proccesing of: S1A_IW_GRDH_1SDV_20210331T000751_20210331T000816_037235_0462B3_4A2D\n",
      "ERROR: An error occured during proccesing of: S1A_IW_GRDH_1SDV_20210331T000726_20210331T000751_037235_0462B3_6292\n",
      "ERROR: An error occured during proccesing of: S1A_IW_GRDH_1SDV_20210331T000751_20210331T000816_037235_0462B3_4A2D\n",
      "ERROR: An error occured during proccesing of: S1A_IW_GRDH_1SDV_20210331T000726_20210331T000751_037235_0462B3_6292\n",
      "ERROR: An error occured during proccesing of: S1A_IW_GRDH_1SDV_20210331T000751_20210331T000816_037235_0462B3_4A2D\n",
      "I0512 10:59:50.654202 139920513722176 s1processor.py:126] Creating Sentinel-1 vrt and geotiff file(s) for date and abs orbit: 20210331_037235\n",
      "\n",
      "\u001b[m\u001b[1;30m--------------------------------------------------------------------------------\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m103 \u001b[1;34m<module>\n",
      "\u001b[m\u001b[1;37mapp.run(main)\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m300 \u001b[1;34mrun\n",
      "\u001b[m\u001b[1;37m_run_main(main, args)\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m251 \u001b[1;34m_run_main\n",
      "\u001b[m\u001b[1;37msys.exit(main(argv))\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mapp.py \u001b[1;32m89 \u001b[1;34mmain\n",
      "\u001b[m\u001b[1;37mprocesspipeliner.process_products()\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36mprocesspipeliner.py \u001b[1;32m44 \u001b[1;34mprocess_products\n",
      "\u001b[m\u001b[1;37ms1processor.create_vrt_and_cog(product_date_abs_orbit)\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;36ms1processor.py \u001b[1;32m130 \u001b[1;34mcreate_vrt_and_cog\n",
      "\u001b[m\u001b[1;37mrgb_path = list((product['product_path'].values[0] / 'processed').glob('*RGB.tif*'))[0]\n",
      "\u001b[m\n",
      "\u001b[m\u001b[1;31mIndexError:\n",
      "\u001b[1;33mlist index out of range\n",
      "\u001b[m\u001b[0m"
     ]
    }
   ],
   "source": [
    "inputPath = '/workspace/data_landset8/unzipped/Forest/BC/LC80200462014005LGN00/LC80200462014005LGN00.geojson'\n",
    "output = '/workspace/data_landset8/unzipped/Forest/BC/LC80200462014005LGN00/'\n",
    "downloadBiome(inputPath,output,logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:07:50.990240Z",
     "start_time": "2021-05-17T07:07:50.985360Z"
    }
   },
   "outputs": [],
   "source": [
    "from arosics import COREG\n",
    "import arosics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T07:07:51.462474Z",
     "start_time": "2021-05-17T07:07:51.451909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arosics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
